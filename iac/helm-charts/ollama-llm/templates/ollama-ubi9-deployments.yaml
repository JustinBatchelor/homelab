---
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: ollama-models
#   namespace: ollama
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: ollama-models
#   template:
#     metadata:
#       labels:
#         app: ollama-models
#     spec:
#       containers:
#         - name: ollama-models
#           image: {{ .Values.ollama.image }}
#           ports:
#             - containerPort: 11434
#               protocol: TCP
#           volumeMounts:
#             - name: ollama-storage
#               mountPath: /root/.ollama
#           resources: {}
#           terminationMessagePath: /dev/termination-log
#           terminationMessagePolicy: File
#           imagePullPolicy: IfNotPresent
#           readinessProbe:
#             exec:
#               command:
#                 - /bin/sh
#                 - -c
#                 - |
#                   # wait until ollama is installed
#                   ollama --version
#       restartPolicy: Always
#       terminationGracePeriodSeconds: 30
#       dnsPolicy: ClusterFirst
#       securityContext: {}
#       schedulerName: default-scheduler
#       volumes:
#         - name: ollama-storage
#           persistentVolumeClaim:
#             claimName: ollama-storage
#   strategy:
#     type: Recreate

kind: Deployment
apiVersion: apps/v1
metadata:
  name: ollama-models
  namespace: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama-models
  template:
    metadata:
      labels:
        app: ollama-models
    spec:
      initContainers:
        - name: install-ollama
          image: 'quay.io/rh-aiservices-bu/ollama-ubi9@sha256:900a74cb65f26d074ba1d18cc150a69007a3893597141622a9770d0c79ec5e22'
          volumeMounts:
            - name: ollama-storage
              mountPath: /root/.ollama
      containers:
        - name: ollama-models
          image: 'quay.io/rh-aiservices-bu/ollama-ubi9@sha256:900a74cb65f26d074ba1d18cc150a69007a3893597141622a9770d0c79ec5e22'
          ports:
            - containerPort: 11434
              protocol: TCP
          resources: {}
          volumeMounts:
            - name: ollama-storage
              mountPath: /root/.ollama
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          imagePullPolicy: IfNotPresent
          command: ["/usr/bin/ollama"]
          args: ["run phi3 && sleep 30 && ollama run phi3"]
      volumes:
        - name: ollama-storage
          persistentVolumeClaim:
            claimName: ollama-storage
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
      securityContext: {}
      schedulerName: default-scheduler
  strategy:
    type: Recreate
  revisionHistoryLimit: 10
  progressDeadlineSeconds: 600
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-storage
  namespace: ollama
  annotations:
    argocd.argoproj.io/sync-wave: "5"
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
kind: Service
apiVersion: v1
metadata:
  name: ollama-models
  namespace: ollama
  annotations:
    argocd.argoproj.io/sync-wave: "5"
spec:
  selector:
    app: ollama-models
  ipFamilies:
    - IPv4
  ports:
    - name: 11434-tcp
      protocol: TCP
      port: 11434
      targetPort: 11434
  internalTrafficPolicy: Cluster
  type: ClusterIP
  ipFamilyPolicy: SingleStack
  sessionAffinity: None
---
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: ollama-models
  namespace: ollama
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  host: "ollama-models.apps.sno.batchelor.live"
  to:
    kind: Service
    name: ollama-models
    weight: 100
  port:
    targetPort: 11434-tcp
  tls:
    termination: edge
  wildcardPolicy: None